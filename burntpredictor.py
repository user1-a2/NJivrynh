# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zhZfNCWi4RIU9sexGGcu4NZMhtti8VT3
"""

# Library Used For This Machine Learning
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestRegressor  # Used instead of LightGBM
from mne_report import generate_feature_distribution_report

# Parent Class 
class BasePreprocessor:
    def __init__(self, path: str):
        self.path = path
        self.data = None

    def load_data(self):
        self.data = pd.read_csv(self.path)
        print("Data loaded with shape:", self.data.shape)

    def feature_engineering(self):
        df = self.data.copy()
        df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2
        df['Intensity'] = df['Heart_Rate'] / df['Duration']
        df['Heart_Rate_X_Duration'] = df['Heart_Rate'] * df['Duration']
        df['Body_Temp_X_Duration'] = df['Body_Temp'] * df['Duration']
        df['Heart_Rate_X_Body_Temp'] = df['Heart_Rate'] * df['Body_Temp']
        df['Heart_Rate_X_Body_Temp_X_Duration'] = df['Heart_Rate'] * df['Body_Temp'] * df['Duration']
        df['Weight_X_Duration'] = df['Weight'] * df['Duration']
        df['Weight_Duration'] = df['Duration'] / df['Weight']
        df['Body_Temp2'] = df['Body_Temp'] ** 0.5
        self.data = df

# Inherit from parent class, also add modelling and visualization
class CaloriePredictor(BasePreprocessor):
    def __init__(self, path):
        super().__init__(path)
        self.model = RandomForestRegressor(n_estimators=300, max_depth=10, random_state=1)

    # Train model based on a Random Forest Regressor to predict calories
    def train_model(self):
        print("\nðŸ§  Training Model...")

        # Drop non-numeric columns
        X = self.data.drop(columns=['Calories'])
        X = X.select_dtypes(include=[np.number])  # Keep only numeric columns

        y = np.log1p(self.data['Calories'])  # log1p for better regression handling

        model = RandomForestRegressor(n_estimators=100, random_state=42)

        scores = cross_validate(
            model, X, y,
            scoring=['r2', 'neg_mean_absolute_error'],
            cv=5,
            return_train_score=True
        )

        print("\nâœ… Model Training Completed. Mean Scores:")
        for key in scores:
            print(f"{key}: {np.mean(scores[key]):.4f}")

    # Creates a correlation heatmap between all numeric features.
    def visualize_distribution(self):
        numeric_data = self.data.select_dtypes(include=[np.number])
        sns.heatmap(numeric_data.corr(), annot=True, fmt='.2f', cmap='coolwarm')
        plt.title("Feature Correlation")
        plt.show()

    # Plots the KDE (distribution) plots for each feature, giving a visual summary of the data spread to user
    def plot_feature_distributions(self):
        import math

        numeric_data = self.data.select_dtypes(include=[np.number])
        num_cols = numeric_data.columns
        n = len(num_cols)

        # Layout settings
        n_cols = 2  # Fewer columns = taller, more readable plots
        n_rows = math.ceil(n / n_cols)
        fig_width = 7 * n_cols
        fig_height = 4 * n_rows

        fig, ax = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height))
        ax = ax.flatten()

        for i, col in enumerate(num_cols):
            sns.kdeplot(data=numeric_data, x=col, ax=ax[i], fill=True)
            ax[i].set_title(f'Distribution of {col}', fontsize=12)
            ax[i].tick_params(axis='x', labelrotation=30)
            ax[i].set_xlabel("")
            ax[i].set_ylabel("")

        # Hide any unused axes
        for j in range(i + 1, len(ax)):
            ax[j].axis("off")

        plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Increase spacing
        plt.show()


# === Usage ===
csv_path = r"C:\Users\User\IdeaProjects\NJivrynh\calories.csv"
predictor = CaloriePredictor(csv_path)
predictor.load_data()
predictor.feature_engineering()
predictor.visualize_distribution()
predictor.plot_feature_distributions()
predictor.train_model()

generate_feature_distribution_report(predictor.data)
